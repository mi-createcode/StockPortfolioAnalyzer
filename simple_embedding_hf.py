from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings  # ìˆ˜ì •ëœ import

def create_simple_vectorstore():
    """ê°„ë‹¨í•œ ë²¡í„° ì €ì¥ì†Œ ë§Œë“¤ê¸° (HuggingFace ë¡œì»¬ ì„ë² ë”©)"""
    try:
        print("ğŸ¤– HuggingFace ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ì²« ì‹¤í–‰ì‹œ ì‹œê°„ ì†Œìš”)")
        
        # HuggingFace ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        model_name = "sentence-transformers/all-MiniLM-L6-v2"  # ê°€ë³ê³  ë¹ ë¦„
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': 'cpu'},  # CPU ì‚¬ìš© ëª…ì‹œ
            encode_kwargs={'normalize_embeddings': True}  # ì •ê·œí™”
        )
        
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

        # ìƒ˜í”Œ ë¬¸ì„œë“¤ - ì£¼ì‹/íˆ¬ì ê´€ë ¨ìœ¼ë¡œ ë³€ê²½
        sample_texts = [
            "ì• í”Œì˜ ì•„ì´í° íŒë§¤ê°€ ì¦ê°€í•˜ê³  ìˆìœ¼ë©° ì£¼ê°€ ìƒìŠ¹ ìš”ì¸ìœ¼ë¡œ ì‘ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "í…ŒìŠ¬ë¼ì˜ ì „ê¸°ì°¨ ë°°í„°ë¦¬ ê¸°ìˆ  ë°œì „ìœ¼ë¡œ íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.", 
            "ì‚¼ì„±ì „ìì˜ ë°˜ë„ì²´ ì‚¬ì—…ì´ í˜¸ì¡°ë¥¼ ë³´ì´ë©° ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ìˆ˜ìš”ê°€ ê¸‰ì¦í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì—”ë¹„ë””ì•„ì˜ AI ì¹© ìˆ˜ìš” ê¸‰ì¦ìœ¼ë¡œ ì£¼ì‹ ì‹œì¥ì—ì„œ í° ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì• í”Œ ì£¼ì‹ì˜ ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ìƒìŠ¹ ì¶”ì„¸ê°€ ì§€ì†ë  ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤."
        ]

        print("ğŸ“ ìƒ˜í”Œ ë¬¸ì„œ ì„ë² ë”© ì¤‘...")

        # Document ê°ì²´ë¡œ ë³€í™˜
        documents = []
        for i, text in enumerate(sample_texts):
            doc = Document(
                page_content=text, 
                metadata={
                    'id': i, 
                    'topic': 'stock_analysis',
                    'source': 'sample_data'
                }
            )
            documents.append(doc)

        # FAISS ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = FAISS.from_documents(documents, embeddings)
        print("âœ… ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì™„ë£Œ!")

        return vectorstore

    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì—ëŸ¬: {e}")
        print("ğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. ì¸í„°ë„· ì—°ê²° í™•ì¸ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”)")
        print("2. pip install sentence-transformers ì‹¤í–‰")
        return None


def test_search(vectorstore):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    queries = [
        "AI ê´€ë ¨ íˆ¬ì",
        "ì „ê¸°ì°¨ ì£¼ì‹",
        "ì• í”Œ ì£¼ê°€ ì „ë§",
        "ë°˜ë„ì²´ íˆ¬ì ê¸°íšŒ",
        "ê¸°ìˆ ì  ë¶„ì„"
    ]

    for query in queries:
        print(f"\nğŸ” '{query}' ê²€ìƒ‰ ê²°ê³¼:")
        results = vectorstore.similarity_search(query, k=2)

        for i, doc in enumerate(results, 1):
            print(f"  {i}. {doc.page_content}")
            print(f"     ë©”íƒ€ë°ì´í„°: {doc.metadata}")


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§  HuggingFace ë¬´ë£Œ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘!")
    print("ğŸ’° ë¹„ìš©: ì™„ì „ ë¬´ë£Œ!")

    vectorstore = create_simple_vectorstore()

    if vectorstore:
        print("\nğŸ‰ ì„±ê³µ! ë¬´ë£Œ ë²¡í„° ì €ì¥ì†Œ ì™„ì„±!")
        test_search(vectorstore)

        # ë²¡í„° ì €ì¥ì†Œ ì €ì¥
        print("\nğŸ’¾ ë²¡í„° ì €ì¥ì†Œ ë¡œì»¬ ì €ì¥ ì¤‘...")
        vectorstore.save_local("portfolio_vectorstore_free")
        print("âœ… ì €ì¥ ì™„ë£Œ: portfolio_vectorstore_free í´ë”")
        
        print("\nğŸš€ ë‚´ì¼ì€ ì´ ë²¡í„° ì €ì¥ì†Œë¥¼ FastAPIì™€ ì—°ê²°í•  ì˜ˆì •!")

    else:
        print("âŒ ë²¡í„° ì €ì¥ì†Œ ìƒì„± ì‹¤íŒ¨")